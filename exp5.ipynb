{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1qJo-wp3cT8qpxYPT9U3LQvy7CdN7tl3F","authorship_tag":"ABX9TyNM03y8U4H+yGDK5N0K8iOP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from nltk.corpus import stopwords\n","from sklearn.metrics.pairwise import cosine_similarity\n"],"metadata":{"id":"2kJ4fow0DOnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DsSf4qB9Dw7C","executionInfo":{"status":"ok","timestamp":1698593456362,"user_tz":-330,"elapsed":669,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"486936c8-fe58-483e-9bdc-45adc4822a54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"],"metadata":{"id":"jc2Gt_i2Dzpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Tokenization and converting to lowercase\n","    tokens = text.lower().split()\n","    # Removing stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","# Apply preprocessing to the dataset\n","preprocessed_data = [preprocess_text(text) for text in newsgroups.data]\n","\n","# Print a preprocessed document as an example\n","print(preprocessed_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQGhKjmoEVOI","executionInfo":{"status":"ok","timestamp":1698593749940,"user_tz":-330,"elapsed":4905,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"5d733fd6-452c-4094-c5e8-8a3e1aa0b084"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sure bashers pens fans pretty confused lack kind posts recent pens massacre devils. actually, bit puzzled bit relieved. however, going put end non-pittsburghers' relief bit praise pens. man, killing devils worse thought. jagr showed much better regular season stats. also lot fo fun watch playoffs. bowman let jagr lot fun next couple games since pens going beat pulp jersey anyway. disappointed see islanders lose final regular season game. pens rule!!!\n"]}]},{"cell_type":"code","source":["# Create a TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","\n","# Fit and transform the preprocessed data\n","tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_data)\n","\n","# Print the shape of the term-document matrix\n","print(\"Shape of the term-document matrix:\", tfidf_matrix.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRCfpJPEE6Q6","executionInfo":{"status":"ok","timestamp":1698593913940,"user_tz":-330,"elapsed":9280,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"1db448e1-322f-43d6-99bd-c66c1976425d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the term-document matrix: (18846, 134409)\n"]}]},{"cell_type":"code","source":["# Define the number of topics (components) to retain\n","num_topics = 100\n","\n","# Apply SVD to the term-document matrix\n","svd = TruncatedSVD(n_components=num_topics)\n","lsa_matrix = svd.fit_transform(tfidf_matrix)\n","# Print the shape of the LSA matrix\n","print(\"Shape of the LSA matrix:\", lsa_matrix.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwlSkVejFhVb","executionInfo":{"status":"ok","timestamp":1698594719519,"user_tz":-330,"elapsed":14665,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"ce786283-c2da-4a81-d70b-d1db8335bd57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the LSA matrix: (18846, 100)\n"]}]},{"cell_type":"code","source":["# Get singular vectors and terms\n","singular_vectors = svd.components_\n","feature_names = tfidf_vectorizer.get_feature_names_out()\n","\n","# Find the indices of the top singular values\n","top_topics = [i for i in range(num_topics)]\n","topics_to_analyze = [0, 1, 2, 3, 4]\n","# Analyze the topics and their top terms\n","for topic_num in topics_to_analyze:\n","    # Get the top terms for this topic\n","    top_term_indices = singular_vectors[topic_num].argsort()[::-1][:10]\n","    top_terms = [feature_names[i] for i in top_term_indices]\n","\n","    print(f\"Topic {topic_num}:\")\n","    print(\", \".join(top_terms))\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rA1gcy3FrnT","executionInfo":{"status":"ok","timestamp":1698600300259,"user_tz":-330,"elapsed":420,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"fda42450-866a-420b-d76e-79b6044fa225"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic 0:\n","would, one, like, people, know, it, get, think, could, time\n","\n","Topic 1:\n","windows, thanks, drive, card, dos, please, file, anyone, mail, software\n","\n","Topic 2:\n","god, jesus, windows, bible, thanks, christ, christian, faith, christians, believe\n","\n","Topic 3:\n","drive, god, scsi, ide, card, hard, disk, controller, drives, game\n","\n","Topic 4:\n","key, drive, government, chip, scsi, system, encryption, use, clipper, keys\n","\n"]}]},{"cell_type":"code","source":["query = [\"Hello world\"]  # Place the query text inside a list\n","\n","# Preprocess the query\n","query_tfidf = tfidf_vectorizer.transform(query)\n","\n","# Project the query into LSI space using the singular vectors\n","query_lsi = svd.transform(query_tfidf)\n","\n","# Compute cosine similarity between the query and all documents\n","cosine_similarities = cosine_similarity(query_lsi, lsa_matrix)  # Use lsa_matrix, which contains LSI-transformed documents\n","\n","# Sort documents by similarity in descending order\n","most_similar_indices = cosine_similarities[0].argsort()[::-1]\n","\n","# Print the most relevant documents\n","top_k = 10  # You can adjust the number of top documents you want to retrieve\n","for i, idx in enumerate(most_similar_indices[:top_k]):\n","    print(f\"Top-{i + 1} Document:\")\n","    print(newsgroups.data[idx])  # Print the content of the document\n","    print(f\"Cosine Similarity: {cosine_similarities[0][idx]}\")\n","    print()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBgynOAcGQU1","executionInfo":{"status":"ok","timestamp":1698602649013,"user_tz":-330,"elapsed":598,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"eb8f3d82-f945-4394-94ad-f94ea3d05b1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top-1 Document:\n","Hello,\n","Cosine Similarity: 0.6995243252324693\n","\n","Top-2 Document:\n","Hello,\n","Cosine Similarity: 0.6995243252324693\n","\n","Top-3 Document:\n","hello testing\n","\n","\n","\n","Cosine Similarity: 0.668525470825247\n","\n","Top-4 Document:\n","\n","Take up residence in a fantasy world. \n","\n","Cosine Similarity: 0.6094752789555774\n","\n","Top-5 Document:\n","\n","\n","Note that the two tables don't talk about the same population.  One is\n","Fortune 1000 companies favoring the platform as their primary\n","application platform, the other is sales (to everyone, not just\n","Fortune 1000).  Fortune 1000 companies don't do a lot of development\n","with the Mac as their top platform.  I would expect that that would\n","explain the discrepancy.\n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.5392580255883939\n","\n","Top-6 Document:\n","\n","\n","You missed something.  I think it takes off vertically and is intended\n","to land the same way.\n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.5328289303092401\n","\n","Top-7 Document:\n","\n","\n","No, it does not.\n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.5293403875062034\n","\n","Top-8 Document:\n","\n","\n","\n","American, perhaps, but nothing military about it.  I learned (mostly)\n","slugs when we talked English units in high school physics and while\n","the teacher was an ex-Navy fighter jock the book certainly wasn't\n","produced by the military.\n","\n","[Poundals were just too flinking small and made the math come out\n","funny; sort of the same reason proponents of SI give for using that.] \n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.5167555293701185\n","\n","Top-9 Document:\n","\n","\n","\n","\n","Careful.  Making statements about how solid state is (generally) more\n","reliable than analog will get you a nasty follow-up from Tommy Mac or\n","Pat.  Wait a minute; you *are* Pat.  Pleased to see that you're not\n","suffering from the bugaboos of a small mind.  ;-)\n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.516132921417346\n","\n","Top-10 Document:\n","\n","\n","And most definitely read it in conjunction with Heinlein's _Starship\n","Trooper_.  The two books are radically different viewpoints of the\n","same basic premises.  I've even heard tell of English classes built\n","around this.\n","\n","-- \n","\"Insisting on perfect safety is for people who don't have the balls to live\n"," in the real world.\"   -- Mary Shafer, NASA Ames Dryden\n","Cosine Similarity: 0.511051750833512\n","\n"]}]},{"cell_type":"code","source":["# Clustering using K-Means and Evaluation\n","from sklearn.cluster import KMeans\n","from sklearn.metrics.cluster import normalized_mutual_info_score\n","from sklearn.metrics import silhouette_score\n","# Apply K-Means clustering to the LSI-transformed data\n","n_clusters = 20  # Adjust the number of clusters as needed\n","kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n","predicted_labels = kmeans.fit_predict(lsa_matrix)\n","silhouette_avg = silhouette_score(lsa_matrix, predicted_labels)\n","\n","print(f\"Silhouette Score:, {silhouette_avg:.4f}\")\n","# Calculate Normalized Mutual Information (NMI) with the true labels (true_labels) and predicted cluster assignments\n","nmi = normalized_mutual_info_score(true_labels, predicted_labels)\n","\n","print(f\"Normalized Mutual Information (NMI):, {nmi:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTUO7onPG4Ky","executionInfo":{"status":"ok","timestamp":1698608486119,"user_tz":-330,"elapsed":18623,"user":{"displayName":"Archit Verma","userId":"00011782670312656860"}},"outputId":"98ac55e5-3f20-47ac-a65e-11b09e4a2170"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Silhouette Score:, 0.0492\n","Normalized Mutual Information (NMI):, 0.3072\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7-vPfwK_XFUF"},"execution_count":null,"outputs":[]}]}